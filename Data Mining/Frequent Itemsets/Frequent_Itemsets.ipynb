{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent Itemset\n",
    "\n",
    "## Overview of frequent itemset method:\n",
    "1. Brute Force\n",
    "  1. Triangular Matrix\n",
    "  2. Triples List\n",
    "  \n",
    "2. A priori\n",
    "\n",
    "3. SON\n",
    "  \n",
    "## Dataset\n",
    "We will be using http://ocelma.net/MusicRecommendationDataset/lastfm-360K.html\n",
    "\n",
    "We could make a sample of this dataset for facilitate development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take first 10000 lines for development\n",
    "!head -n 10000 usersha1-artmbid-artname-plays.tsv > sample.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import collections\n",
    "import itertools\n",
    "import math\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Find  artists pair with support > 10, using Triangular Matrix method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='sample.tsv'\n",
    "threshold=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(text):\n",
    "    tokens=[t for t in text.split('\\t') if t!='']\n",
    "    if len(tokens)!=4:\n",
    "        return []\n",
    "    else:\n",
    "        return [tokens[:2]]\n",
    "\n",
    "def get_baskets_spark(filename):\n",
    "    # Can't use the same logic as in pure python, because spark will read file in parallel.\n",
    "    # Use groupByKey to merge artist_id liked by the same user_id into a list.\n",
    "    # Another benfits is, this logic allows the file lines been shuffled, which is not allowed in the python logic\n",
    "    sc = SparkContext(\"local\",\"PySpark Tutorial\") #In Q1, Q2, Q3, Q4 spark is only used for reading data\n",
    "\n",
    "    # Use only 1 core\n",
    "    baskets=sc.textFile(filename,minPartitions=1).flatMap(lambda x:process_line(x)).groupByKey().collect()\n",
    "\n",
    "    sc.stop()\n",
    "    return baskets\n",
    "\n",
    "def get_item_dict(baskets):\n",
    "    item_dict={}\n",
    "    for basket in baskets:\n",
    "        for item in basket[1]:\n",
    "            if item not in item_dict.keys():\n",
    "                item_dict[item]=len(item_dict)\n",
    "    return item_dict\n",
    "\n",
    "def inverse_dict(d):\n",
    "    return {v:k for k,v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets=get_baskets_spark(filename)\n",
    "item_dict=get_item_dict(baskets)\n",
    "item_dict_inv=inverse_dict(item_dict)\n",
    "n=len(item_dict)\n",
    "\n",
    "tri_matrix=[0 for i in range(n*(n-1)//2)]\n",
    "for basket in baskets:\n",
    "    items=basket[1]\n",
    "    for pair in itertools.combinations(items,2):\n",
    "        i=item_dict[pair[0]]\n",
    "        j=item_dict[pair[1]]\n",
    "        if i>j:\n",
    "            i,j=j,i\n",
    "        idx=int((n*(n-1)/2) - (n-i)*((n-i)-1)/2 + j - i - 1)\n",
    "        tri_matrix[idx]+=1\n",
    "    \n",
    "frequent_itemset_list=[]\n",
    "for idx in range(len(tri_matrix)):\n",
    "    count=tri_matrix[idx]\n",
    "    if count>=threshold:\n",
    "        i = int(n - 2 - math.floor(math.sqrt(-8*idx + 4*n*(n-1)-7)/2.0 - 0.5))\n",
    "        j = int(idx + i + 1 - n*(n-1)/2 + (n-i)*((n-i)-1)/2)\n",
    "        item_i=item_dict_inv[i]\n",
    "        item_j=item_dict_inv[j]\n",
    "        if item_i>item_j:\n",
    "            item_i,item_j=item_j,item_i\n",
    "        frequent_itemset_list.append(((item_i,item_j),count))\n",
    "frequent_itemset_list=sorted(frequent_itemset_list,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'cc197bad-dc9c-440d-a5b5-d52ba2e14234'),\n",
       "  18),\n",
       " (('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d'),\n",
       "  18),\n",
       " (('52074ba6-e495-4ef3-9bb4-0703888a9f68',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  14),\n",
       " (('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'f6f2326f-6b25-4170-b89d-e235b25508e8'),\n",
       "  14),\n",
       " (('8f6bd1e4-fbe1-4f50-aa9b-94c450ec0f11',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  13),\n",
       " (('8c538f11-c141-4588-8ecb-931083524186',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  13),\n",
       " (('72c536dc-7137-4477-a521-567eeb840fa8',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  13),\n",
       " (('b071f9fa-14b0-4217-8e97-eb41da73f598',\n",
       "   'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d'),\n",
       "  12),\n",
       " (('9c9f1380-2516-4fc9-a3e6-f9f61941d090',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  12),\n",
       " (('1cc5adcd-1422-4b5c-a3cd-3ecd4f43f506',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  12),\n",
       " (('69ee3720-a7cb-4402-b48d-a02c366f2bcf',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  12),\n",
       " (('8bfac288-ccc5-448d-9573-c33ea2aa5c30',\n",
       "   'cc197bad-dc9c-440d-a5b5-d52ba2e14234'),\n",
       "  11),\n",
       " (('847e8284-8582-4b0e-9c26-b042a4f49e57',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  11),\n",
       " (('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'b071f9fa-14b0-4217-8e97-eb41da73f598'),\n",
       "  10),\n",
       " (('a3cb23fc-acd3-4ce0-8f36-1e5aa6a18432',\n",
       "   'cc197bad-dc9c-440d-a5b5-d52ba2e14234'),\n",
       "  10),\n",
       " (('8c538f11-c141-4588-8ecb-931083524186',\n",
       "   'cc197bad-dc9c-440d-a5b5-d52ba2e14234'),\n",
       "  10),\n",
       " (('cc197bad-dc9c-440d-a5b5-d52ba2e14234',\n",
       "   'f82f3a3e-29c2-42ca-b589-bc5dc210fa9e'),\n",
       "  10),\n",
       " (('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'c485632c-b784-4ee9-8ea1-c5fb365681fc'),\n",
       "  10),\n",
       " (('0c751690-c784-4a4f-b1e4-c1de27d47581',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('31745282-b1ea-4d62-939f-226b14d68e7c',\n",
       "   'f57e14e4-b030-467c-b202-539453f504ec'),\n",
       "  10),\n",
       " (('5441c29d-3602-4898-b1a1-b77fa23b8e50',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('0af78501-5647-4c18-9a0d-66ac8789e13b',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('9a58fda3-f4ed-4080-a3a5-f457aac9fcdd',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('6c8b9855-ba8b-48f9-ac1d-42167f7f7b18',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('678d88b2-87b0-403b-b63d-5da7465aecc3',\n",
       "   'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d'),\n",
       "  10),\n",
       " (('b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d',\n",
       "   'd43d12a1-2dc9-4257-a2fd-0a3bb1081b86'),\n",
       "  10),\n",
       " (('72c536dc-7137-4477-a521-567eeb840fa8',\n",
       "   'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d'),\n",
       "  10),\n",
       " (('678d88b2-87b0-403b-b63d-5da7465aecc3',\n",
       "   '83d91898-7763-47d7-b03b-b92132375c47'),\n",
       "  10)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(frequent_itemset_list))\n",
    "frequent_itemset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Find  artists pair with support > 10, using Triples List method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstList(collections.UserList):\n",
    "    def __lt__(self,other):\n",
    "        return self[0].__lt__(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets=get_baskets_spark(filename)\n",
    "item_dict=get_item_dict(baskets)\n",
    "item_dict_inv=inverse_dict(item_dict)\n",
    "n=len(item_dict)\n",
    "\n",
    "tuples=[]\n",
    "for basket in baskets:\n",
    "    items=basket[1]\n",
    "    for pair in itertools.combinations(items,2):\n",
    "        i=item_dict[pair[0]]\n",
    "        j=item_dict[pair[1]]\n",
    "        if i>j:\n",
    "            i,j=j,i\n",
    "        idx=n*i+j\n",
    "        idx_insert=bisect.bisect_left(tuples,idx)\n",
    "        if idx_insert>=len(tuples):\n",
    "            tuples.append(FirstList([idx,1]))\n",
    "        else:\n",
    "            tp=tuples[idx_insert]\n",
    "            if tp[0]==idx:\n",
    "                tp[1]+=1\n",
    "            else:\n",
    "                tuples.insert(idx_insert,FirstList([idx,1]))\n",
    "        \n",
    "frequent_itemset_list=[]\n",
    "for idx,count in tuples:\n",
    "    if count>=threshold:\n",
    "        i = idx//n\n",
    "        j = idx%n\n",
    "        item_i=item_dict_inv[i]\n",
    "        item_j=item_dict_inv[j]\n",
    "        if item_i>item_j:\n",
    "            item_i,item_j=item_j,item_i\n",
    "        frequent_itemset_list.append(((item_i,item_j),count))\n",
    "frequent_itemset_list=sorted(frequent_itemset_list,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'cc197bad-dc9c-440d-a5b5-d52ba2e14234'),\n",
       "  18),\n",
       " (('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d'),\n",
       "  18),\n",
       " (('52074ba6-e495-4ef3-9bb4-0703888a9f68',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  14),\n",
       " (('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'f6f2326f-6b25-4170-b89d-e235b25508e8'),\n",
       "  14),\n",
       " (('8f6bd1e4-fbe1-4f50-aa9b-94c450ec0f11',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  13),\n",
       " (('8c538f11-c141-4588-8ecb-931083524186',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  13),\n",
       " (('72c536dc-7137-4477-a521-567eeb840fa8',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  13),\n",
       " (('b071f9fa-14b0-4217-8e97-eb41da73f598',\n",
       "   'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d'),\n",
       "  12),\n",
       " (('9c9f1380-2516-4fc9-a3e6-f9f61941d090',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  12),\n",
       " (('1cc5adcd-1422-4b5c-a3cd-3ecd4f43f506',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  12),\n",
       " (('69ee3720-a7cb-4402-b48d-a02c366f2bcf',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  12),\n",
       " (('8bfac288-ccc5-448d-9573-c33ea2aa5c30',\n",
       "   'cc197bad-dc9c-440d-a5b5-d52ba2e14234'),\n",
       "  11),\n",
       " (('847e8284-8582-4b0e-9c26-b042a4f49e57',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  11),\n",
       " (('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'b071f9fa-14b0-4217-8e97-eb41da73f598'),\n",
       "  10),\n",
       " (('a3cb23fc-acd3-4ce0-8f36-1e5aa6a18432',\n",
       "   'cc197bad-dc9c-440d-a5b5-d52ba2e14234'),\n",
       "  10),\n",
       " (('8c538f11-c141-4588-8ecb-931083524186',\n",
       "   'cc197bad-dc9c-440d-a5b5-d52ba2e14234'),\n",
       "  10),\n",
       " (('cc197bad-dc9c-440d-a5b5-d52ba2e14234',\n",
       "   'f82f3a3e-29c2-42ca-b589-bc5dc210fa9e'),\n",
       "  10),\n",
       " (('a74b1b7f-71a5-4011-9441-d0b5e4122711',\n",
       "   'c485632c-b784-4ee9-8ea1-c5fb365681fc'),\n",
       "  10),\n",
       " (('0c751690-c784-4a4f-b1e4-c1de27d47581',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('31745282-b1ea-4d62-939f-226b14d68e7c',\n",
       "   'f57e14e4-b030-467c-b202-539453f504ec'),\n",
       "  10),\n",
       " (('5441c29d-3602-4898-b1a1-b77fa23b8e50',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('0af78501-5647-4c18-9a0d-66ac8789e13b',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('9a58fda3-f4ed-4080-a3a5-f457aac9fcdd',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('6c8b9855-ba8b-48f9-ac1d-42167f7f7b18',\n",
       "   'a74b1b7f-71a5-4011-9441-d0b5e4122711'),\n",
       "  10),\n",
       " (('678d88b2-87b0-403b-b63d-5da7465aecc3',\n",
       "   'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d'),\n",
       "  10),\n",
       " (('b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d',\n",
       "   'd43d12a1-2dc9-4257-a2fd-0a3bb1081b86'),\n",
       "  10),\n",
       " (('72c536dc-7137-4477-a521-567eeb840fa8',\n",
       "   'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d'),\n",
       "  10),\n",
       " (('678d88b2-87b0-403b-b63d-5da7465aecc3',\n",
       "   '83d91898-7763-47d7-b03b-b92132375c47'),\n",
       "  10)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_itemset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Find all frequent items set with support > 10, using A priori method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_counter(baskets):\n",
    "    item_counter=collections.Counter()\n",
    "    for basket in baskets:\n",
    "        items=basket[1]    \n",
    "        item_counter.update(items)\n",
    "    return item_counter\n",
    "\n",
    "def get_item_dict_threshold(item_counter,threshold):\n",
    "    item_dict={}\n",
    "    for item,count in item_counter.items():\n",
    "        if count>=threshold:\n",
    "            item_dict[item]=len(item_dict)\n",
    "    return item_dict\n",
    "\n",
    "def apriori_method(baskets,threshold,method):\n",
    "    item_counter=get_item_counter(baskets)\n",
    "    item_dict=get_item_dict_threshold(item_counter,threshold)\n",
    "    return method(baskets,threshold,item_dict)\n",
    "\n",
    "def tuple_wrapper(t):\n",
    "    if type(t) is not tuple:\n",
    "        t=(t,)\n",
    "    return t\n",
    "\n",
    "def get_possible_k(item_dict, k):\n",
    "    possible_k = {}\n",
    "    for pair in itertools.combinations(item_dict.keys(), 2):\n",
    "        pair_set = set()\n",
    "        for i in range(2):\n",
    "            pair_set = pair_set.union(tuple_wrapper(pair[i]))\n",
    "        if len(pair_set) == k:\n",
    "            possible_k[frozenset(pair_set)] = [pair[0], pair[1]]\n",
    "    return possible_k\n",
    "\n",
    "def get_dict_from_frequent(frequent):\n",
    "    item_dict={}\n",
    "    for item in frequent:\n",
    "        item_dict[item]=len(item_dict)\n",
    "    return item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_list_method(baskets,threshold,item_dict=None,k=2):\n",
    "    if item_dict==None:\n",
    "        item_dict=get_item_dict(baskets)\n",
    "    else: #apriori, remove infrequent items from baskets\n",
    "        if k==2:\n",
    "            for i in range(len(baskets)):\n",
    "                basket=baskets[i]\n",
    "                items=basket[1]\n",
    "                items_filtered=[i for i in items if i in item_dict.keys()]\n",
    "                baskets[i]=(basket[0],items_filtered)\n",
    "\n",
    "    item_dict_inv=inverse_dict(item_dict)\n",
    "    n=len(item_dict)\n",
    "    \n",
    "    if k>=3:\n",
    "        possible_k=get_possible_k(item_dict,k)\n",
    "\n",
    "    tuples=[]\n",
    "    for basket in baskets:\n",
    "        items=basket[1]\n",
    "        for kpair in itertools.combinations(items,k):\n",
    "            if k>=3:\n",
    "                pair=possible_k.get(frozenset(kpair),None)\n",
    "                if pair==None:\n",
    "                    continue\n",
    "            else:\n",
    "                pair=kpair\n",
    "                \n",
    "            i=item_dict[pair[0]]\n",
    "            j=item_dict[pair[1]]\n",
    "            if i>j:\n",
    "                i,j=j,i\n",
    "            idx=n*i+j\n",
    "            idx_insert=bisect.bisect_left(tuples,idx)\n",
    "            if idx_insert>=len(tuples):\n",
    "                tuples.append(FirstList([idx,1]))\n",
    "            else:\n",
    "                tp=tuples[idx_insert]\n",
    "                if tp[0]==idx:\n",
    "                    tp[1]+=1\n",
    "                else:\n",
    "                    tuples.insert(idx_insert,FirstList([idx,1]))\n",
    "    frequent_itemset_list=[]\n",
    "    for idx,count in tuples:\n",
    "        if count>=threshold:\n",
    "            i = idx//n\n",
    "            j = idx%n\n",
    "            item_i=item_dict_inv[i]\n",
    "            item_j=item_dict_inv[j]\n",
    "            item_all=set()\n",
    "            for item in (item_i,item_j):\n",
    "                item_all=item_all.union(tuple_wrapper(item))\n",
    "            item_all=tuple(sorted(item_all))\n",
    "            frequent_itemset_list.append((item_all,count))\n",
    "    frequent_itemset_list=sorted(frequent_itemset_list,key=lambda x:x[1],reverse=True)\n",
    "    return frequent_itemset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_all_method(baskets,threshold,method):\n",
    "    item_counter=get_item_counter(baskets)\n",
    "    itemsets_1=sorted([(k,v) for k,v in item_counter.items() if v>=threshold],\n",
    "                      key=lambda x:x[1],reverse=True)\n",
    "    frequent_1=[x[0] for x in itemsets_1]\n",
    "    \n",
    "    itemsets_list=[itemsets_1]\n",
    "    frequent_list=frequent_1\n",
    "    \n",
    "    k=2\n",
    "    while True:\n",
    "        item_dict=get_dict_from_frequent(frequent_list)\n",
    "        itemsets=method(baskets,threshold,item_dict,k)\n",
    "        if len(itemsets)>0:\n",
    "            itemsets_list.append(itemsets)\n",
    "            frequent_list.extend([x[0] for x in itemsets])\n",
    "            k+=1\n",
    "            print(f\"k={k} initiated\")\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return itemsets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3 initiated\n",
      "k=4 initiated\n"
     ]
    }
   ],
   "source": [
    "baskets=get_baskets_spark(filename)\n",
    "threshold=7\n",
    "itemsets_list=apriori_all_method(baskets,threshold,triple_list_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_itemsets(itemsets_list):\n",
    "    n_itemsets=len(itemsets_list)\n",
    "    for i in range(n_itemsets-1,-1,-1):\n",
    "        print(f\"# of frequent itemsets of size {i+1}: {len(itemsets_list[i])}\")\n",
    "#         for itemset in itemsets_list[i]:\n",
    "#             print(\"\\t\",itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of frequent itemsets of size 3: 6\n",
      "# of frequent itemsets of size 2: 128\n",
      "# of frequent itemsets of size 1: 207\n"
     ]
    }
   ],
   "source": [
    "print_itemsets(itemsets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Find all frequent items set with support > 10, using SON method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori_all_method(baskets,threshold,method,son=False,tot_baskets=0):\n",
    "    if type(baskets) is not list:\n",
    "        baskets=list(baskets)\n",
    "    if son:\n",
    "        threshold=math.floor(threshold*len(baskets)/tot_baskets)\n",
    "        \n",
    "    item_counter=get_item_counter(baskets)\n",
    "    itemsets_1=sorted([(k,v) for k,v in item_counter.items() if v>=threshold],\n",
    "                      key=lambda x:x[1],reverse=True)\n",
    "    frequent_1=[x[0] for x in itemsets_1]\n",
    "    \n",
    "    itemsets_list=[itemsets_1]\n",
    "    frequent_list=frequent_1\n",
    "    \n",
    "    k=2\n",
    "    while True:\n",
    "        item_dict=get_dict_from_frequent(frequent_list)\n",
    "        itemsets=method(baskets,threshold,item_dict,k)\n",
    "        if len(itemsets)>0:\n",
    "            itemsets_list.append(itemsets)\n",
    "            frequent_list.extend([x[0] for x in itemsets])\n",
    "            k+=1\n",
    "            print(f\"k={k} initiated\")\n",
    "        else:\n",
    "            break\n",
    "    if son:\n",
    "        return frequent_list\n",
    "    else:\n",
    "        return itemsets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_candidates(baskets,candidates):\n",
    "    item_counter=collections.defaultdict(int)\n",
    "    for basket in baskets:\n",
    "        items=frozenset(basket[1])\n",
    "        for candidate in candidates:\n",
    "            if items.issuperset(tuple_wrapper(candidate)):\n",
    "                item_counter[candidate]+=1\n",
    "    return item_counter.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='sample.tsv'\n",
    "threshold=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\",\"PySpark Tutorial\")\n",
    "baskets_rdd=baskets=sc.textFile(filename,minPartitions=2).flatMap(lambda x:process_line(x)).groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_baskets=baskets_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_baskets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates=baskets_rdd.mapPartitions(lambda x:apriori_all_method(x,threshold,triple_list_method,True,tot_baskets))\\\n",
    "            .distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsets=baskets_rdd.mapPartitions(lambda x:count_candidates(x,candidates)).\\\n",
    "         reduceByKey(lambda a,b:a+b).filter(lambda x:x[1]>=threshold).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsets_dict=collections.defaultdict(list)\n",
    "for itemset in itemsets:\n",
    "    k=len(tuple_wrapper(itemset[0]))\n",
    "    itemsets_dict[k].append(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemsets_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 207), (2, 128), (3, 6)]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary=[(k,len(v)) for k,v in itemsets_dict.items()]\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3_6]",
   "language": "python",
   "name": "conda-env-Python3_6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
